Emergent Abilities of Large Language Models
	背景：讨论大模型的新发现的能力（“涌现”）。小模型中没有，只有大模型中才出现的能力； 大模型量变后产生的质变的能力；
		涌现的分类：few-show prompting / 增强prompt策略；
		本文目的不是为了区分达到涌现需要的方法，而是讨论先前工作的涌现行为例子。
	方法：
		few-shot prompt:
			在待预测文本之前，增加input-ouput的例子当作上下文。在中方式在模型的scale到达一定程度后，效果会极具上升，而之前的效果则很随机；
		增强prompt策略：
			虽然few-show是最常见的与大规模lm交互的方式，最近的工作提出了其他几种prompt/ft策略等来增强PLM的能力；
			chian of thought:通过多个中间step，提升模型的推理能力；
			instruction following:执行新任务时，通过读描述task的指令，来提升效果；
	讨论：
		上述的方式都是在足够大的lm上才能体现出来，涌现线性的潜在解释：


		
			
			

A Survey on In-context Learning
	
	总结ICL的进程与挑战（ICL:）
	ICL:通过描述性的自然语言，形成in-context example，这些example形成prompt作为待预测query的前缀，直接做预测，不进行模型训练。 定向挖掘PLM的能力？
	ICL的优势：自然语言，解释性强；不需要训练；
	ICL对设置敏感：如 prompt模板/in-context 样本的选择等
	ICL的warm up: 非必要，但是加了可能效果更好。
	ICL的指令设计：
	