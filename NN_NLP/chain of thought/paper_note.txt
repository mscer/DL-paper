Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
	背景：探索如何生成 chain of thought prompt,即产生一系列的中间推理步骤，来提升大规模语言模型的推理能力。
	动机：预训练LM在数学/常识推理/符号认知没有取得很好的性能；本文探索如何使用简单的方法来提升语言模型的推理能力；
			1 先前已经有了从语言模型中生成语言形式的中间步骤的能力。
			2 简单的prompt 在nlp的一系列qa任务上取得了很好的效果，但是prompt在需要推理的场景，效果比较差；
		本文结合1和2 ，提出具备推理能力的prompt，< input,chain of thougnt,output>，chain of thought 是一系列的中间推理步骤，来提升最终效果。
		chain of thought的好处：复杂问题的分解能力；提升了模型的解释能力；训练简单，在few-shot prompt上加上chain of thought样本就行
	方法：本文目标是生成一系列的chain of thought 来帮助提升推效果。 chain of thought 模拟人类解决问题的过程。
		数学推理：人工组成8个有chain of thought 的few-shot样本;  由于小模型上生成的cot 流畅，但是罗技不通，chain of thought 只在模型参数量接近1000亿上只有才有显著收益
		基线：lambda/palm/codex/gpt3
		结论：cot是大模型才具备的能力（100b，千亿参数量），涌现能力
		消融分析：尝试了数学公式/先答案后步骤/
		鲁棒性：prompt样例的敏感性测试
	
