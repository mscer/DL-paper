On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines
	


Foundation Transformers
	背景: transformer是语言、视觉、语音 和多模态的大融合。但是不同模型用了不同的实现，比如preln postln。 本文提出transfomer的变种，引入sub-layernorm 、初始化策略来支持不同业务。
	动机: transformer逐渐成为统一的模型框架，但是不同任务采用的实现不一样； 另外transfomer的一个痛点是训练稳定性问题； 基于此 文章提出了统一的transformer,适用于多种任务、多模态、并且优化训练稳定性，缓解大模型的训练困难问题。
	核心方法:
		新的ln:结合preln（输入上先做ln）和postln（输出上做ln）：增加subln，输入和输出上分别增加ln。 FNN上也在输入和输出(激活函数之前)上加了LN
		*新的初始化：提出有理论保证的新的初始化策略，
	效果:
		实验： bert、gpt、beit、beit3等。包含encoder-only,decoder-only, vision-language 模型。
		自回归：ICL
		自编码：
		NMT:

	消融实验:
	结论:


World Models 
	背景: 探索世界模型，采用无监督的方式训练， 并学习rl环境的时空压缩表示。训练agent，建立真实世界的仿真器。https://worldmodels.github.io/
	动机: 人类将周遭时空信息进行压缩提取，完成对认知的提取。 在典型的rl问题中，agent也可以从更好的past和future表示中收益。 之前的model-free 参数量太少，评估不够精准。 本文尝试用更大的nn结合bp来训练agent：先无监督训练一个agent，然后训练一个小点的模型来使用agent执行任务。
	核心工作：
	相关工作：
	核心方法:
		agent model:视觉感知模块(vae 进行图片信息的压缩，空间信息)+memory 模块（rnn，时间信息，串联历史信息，做出合理预测）+ 决策模块（mlp）
		1 vae训练：随机生成几轮实验，收集10000张图片； 使用随机agent跑实验即可。使用10000张图片训练vae
		2 mdn-rnn:  混合密度网络输出的rnn模型。 预测下一个画面的隐向量； 输入是vae的向量和动作
		3  决策模块训练：采用cma-es 训练的mlp
		4 训练md-rnn来模拟真实环境
		 
	基线：
		dqn
		a3c
	数据集：
		car比赛实验环境
	效果:
		效果大幅领先其他模型; 之前最高分是 652； 现在能到900.
	消融实验:
		1 只包含v+c:能达到sota，但是效果不稳定
		2 v+m+c: m提供future信息，单独v只有当前时刻的信息，信息量不够。加上好效果很稳定，并且效果提升很多。m可以提供下一个时刻的预测信息，也能减少决策部分的压力。

		3 训练agent(m )来模拟 真实环境。 然后用虚拟的agent来训练 v+m+c
		4 使用在虚拟环境徇烂的agent，在真实环境测试，效果进一步提高。
	结论: